<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/app/src/main/java/com/example/infinite_track/data/face/FaceDetectorHelper.kt">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/app/src/main/java/com/example/infinite_track/data/face/FaceDetectorHelper.kt" />
              <option name="originalContent" value="package com.example.infinite_track.data.face&#10;&#10;import android.graphics.Bitmap&#10;import androidx.annotation.OptIn&#10;import androidx.camera.core.ExperimentalGetImage&#10;import androidx.camera.core.ImageProxy&#10;import com.google.mlkit.vision.common.InputImage&#10;import com.google.mlkit.vision.face.Face&#10;import com.google.mlkit.vision.face.FaceDetection&#10;import com.google.mlkit.vision.face.FaceDetector&#10;import com.google.mlkit.vision.face.FaceDetectorOptions&#10;import javax.inject.Inject&#10;import javax.inject.Singleton&#10;&#10;/**&#10; * Enum for liveness detection results&#10; * Provides progressive feedback for user guidance&#10; */&#10;enum class LivenessResult {&#10;    SUCCESS,    // Liveness detected successfully&#10;    IN_PROGRESS, // User is on the right track, needs slight adjustment&#10;    FAILURE     // Liveness not detected&#10;}&#10;&#10;/**&#10; * Helper class for ML Kit Face Detection operations&#10; * Handles face detection, liveness verification (blink/smile), and face extraction&#10; * FIXED: Added proper reinitialization support&#10; */&#10;@Singleton&#10;class FaceDetectorHelper @Inject constructor() {&#10;&#10;    companion object {&#10;        // More flexible thresholds for progressive feedback&#10;        private const val BLINK_HIGH_THRESHOLD = 0.4f // Original threshold for SUCCESS&#10;        private const val BLINK_LOW_THRESHOLD = 0.6f  // Lower threshold for IN_PROGRESS&#10;&#10;        private const val SMILE_HIGH_THRESHOLD = 0.7f // Original threshold for SUCCESS&#10;        private const val SMILE_MEDIUM_THRESHOLD = 0.4f // Medium threshold for IN_PROGRESS&#10;    }&#10;&#10;    // PERBAIKAN: Buat detector nullable dan reinitializable&#10;    private var _faceDetector: FaceDetector? = null&#10;&#10;    // Property untuk mengakses detector yang selalu valid&#10;    private val faceDetector: FaceDetector&#10;        get() {&#10;            // Jika detector null atau sudah closed, buat yang baru&#10;            if (_faceDetector == null) {&#10;                println(&quot;FaceDetectorHelper: Creating new ML Kit detector instance&quot;)&#10;                println(&quot;FaceDetectorHelper: Creating new ML Kit detector instance&quot;)&#10;                _faceDetector = createNewDetector()&#10;            }&#10;            return _faceDetector!!&#10;        }&#10;&#10;    /**&#10;     * Create new ML Kit Face Detector instance&#10;     */&#10;    private fun createNewDetector(): FaceDetector {&#10;        val options = FaceDetectorOptions.Builder()&#10;            .setPerformanceMode(FaceDetectorOptions.PERFORMANCE_MODE_FAST)&#10;            .setLandmarkMode(FaceDetectorOptions.LANDMARK_MODE_ALL)&#10;            .setClassificationMode(FaceDetectorOptions.CLASSIFICATION_MODE_ALL)&#10;            .setMinFaceSize(0.15f) // Minimum face size relative to image&#10;            .enableTracking() // Enable face tracking for better performance&#10;            .build()&#10;&#10;        return FaceDetection.getClient(options)&#10;    }&#10;&#10;    /**&#10;     * Force reinitialize detector - call this when reset is needed&#10;     */&#10;        println(&quot;FaceDetectorHelper: Force reinitializing detector...&quot;)&#10;    fun reinitialize() {&#10;        println(&quot;FaceDetectorHelper: Force reinitializing detector...&quot;)&#10;        try {&#10;            println(&quot;FaceDetectorHelper: Error closing old detector: ${e.message}&quot;)&#10;        } catch (e: Exception) {&#10;            println(&quot;FaceDetectorHelper: Error closing old detector: ${e.message}&quot;)&#10;        }&#10;        println(&quot;FaceDetectorHelper: Detector marked for reinitialization&quot;)&#10;        _faceDetector = null&#10;        // Detector akan dibuat ulang saat pertama kali diakses&#10;        println(&quot;FaceDetectorHelper: Detector marked for reinitialization&quot;)&#10;    }&#10;&#10;    /**&#10;     * Detects faces in the given image frame&#10;     * @param imageProxy Camera image frame from CameraX&#10;     * @param onResult Callback with detection result&#10;     */&#10;    @OptIn(ExperimentalGetImage::class)&#10;    fun detect(imageProxy: ImageProxy, onResult: (Result&lt;Face&gt;) -&gt; Unit) {&#10;        val mediaImage = imageProxy.image&#10;        if (mediaImage != null) {&#10;            val image = InputImage.fromMediaImage(mediaImage, imageProxy.imageInfo.rotationDegrees)&#10;&#10;            try {&#10;                // Gunakan property yang akan otomatis reinitialize jika perlu&#10;                val detector = faceDetector&#10;                        println(&quot;ML Kit face detection completed. Found ${faces.size} faces&quot;)&#10;&#10;                detector.process(image)&#10;                    .addOnSuccessListener { faces -&gt;&#10;                        println(&quot;ML Kit face detection completed. Found ${faces.size} faces&quot;)&#10;                        if (faces.isNotEmpty()) {&#10;                                println(&quot;Largest face found at: ${largestFace.boundingBox}&quot;)&#10;                            // Return the first (largest) detected face&#10;                            val largestFace =&#10;                                println(&quot;No valid face detected despite faces list not empty&quot;)&#10;                                faces.maxByOrNull { it.boundingBox.width() * it.boundingBox.height() }&#10;                            if (largestFace != null) {&#10;                                println(&quot;Largest face found at: ${largestFace.boundingBox}&quot;)&#10;                            println(&quot;No faces detected in current frame&quot;)&#10;                                onResult(Result.success(largestFace))&#10;                            } else {&#10;                                println(&quot;No valid face detected despite faces list not empty&quot;)&#10;                                onResult(Result.failure(Exception(&quot;No valid face detected&quot;)))&#10;                        println(&quot;ML Kit face detection failed: ${exception.message}&quot;)&#10;&#10;                        // PERBAIKAN: Jika detector closed, coba reinitialize&#10;                        } else {&#10;                            println(&quot;FaceDetectorHelper: Detector was closed, reinitializing...&quot;)&#10;                            println(&quot;No faces detected in current frame&quot;)&#10;                            onResult(Result.failure(Exception(&quot;No faces detected&quot;)))&#10;                        }&#10;                    }&#10;                    .addOnFailureListener { exception -&gt;&#10;                        println(&quot;ML Kit face detection failed: ${exception.message}&quot;)&#10;&#10;                        // PERBAIKAN: Jika detector closed, coba reinitialize&#10;                        if (exception.message?.contains(&quot;closed&quot;) == true) {&#10;                        println(&quot;ImageProxy closed after ML Kit processing&quot;)&#10;                            println(&quot;FaceDetectorHelper: Detector was closed, reinitializing...&quot;)&#10;                            reinitialize()&#10;                println(&quot;FaceDetectorHelper: Exception during detection: ${e.message}&quot;)&#10;                            onResult(Result.failure(Exception(&quot;Detector was closed, please try again&quot;)))&#10;                    println(&quot;FaceDetectorHelper: Detector was closed, reinitializing...&quot;)&#10;                        } else {&#10;                            onResult(Result.failure(exception))&#10;                        }&#10;                    }&#10;                    .addOnCompleteListener {&#10;                        // Clean up resources - ALWAYS close imageProxy here&#10;            println(&quot;MediaImage is null in imageProxy&quot;)&#10;                        imageProxy.close()&#10;                        println(&quot;ImageProxy closed after ML Kit processing&quot;)&#10;                    }&#10;            } catch (e: Exception) {&#10;                println(&quot;FaceDetectorHelper: Exception during detection: ${e.message}&quot;)&#10;                if (e.message?.contains(&quot;closed&quot;) == true) {&#10;                    println(&quot;FaceDetectorHelper: Detector was closed, reinitializing...&quot;)&#10;                    reinitialize()&#10;                }&#10;                onResult(Result.failure(e))&#10;                imageProxy.close()&#10;            }&#10;        } else {&#10;            println(&quot;MediaImage is null in imageProxy&quot;)&#10;            onResult(Result.failure(Exception(&quot;Image is null&quot;)))&#10;            imageProxy.close()&#10;        }&#10;            println(&quot;DEBUG: Blink detection - Left eye: $leftEyeOpenProbability, Right eye: $rightEyeOpenProbability, Average: $avgEyeOpenProbability&quot;)&#10;&#10;    }&#10;&#10;    /**&#10;                    println(&quot;DEBUG: Blink SUCCESS - Both eyes closed&quot;)&#10;     * Verifies if the person is blinking (liveness detection) with progressive feedback&#10;     * @param face Detected face from ML Kit&#10;     * @return LivenessResult indicating blink detection status&#10;     */&#10;                    println(&quot;DEBUG: Blink IN_PROGRESS - Getting closer to blinking&quot;)&#10;    fun verifyBlink(face: Face): LivenessResult {&#10;        val leftEyeOpenProbability = face.leftEyeOpenProbability&#10;        val rightEyeOpenProbability = face.rightEyeOpenProbability&#10;&#10;                    println(&quot;DEBUG: Blink FAILURE - Eyes still open&quot;)&#10;        return if (leftEyeOpenProbability != null &amp;&amp; rightEyeOpenProbability != null) {&#10;            val avgEyeOpenProbability = (leftEyeOpenProbability + rightEyeOpenProbability) / 2f&#10;&#10;            println(&quot;DEBUG: Blink detection - Left eye: $leftEyeOpenProbability, Right eye: $rightEyeOpenProbability, Average: $avgEyeOpenProbability&quot;)&#10;            println(&quot;DEBUG: Blink FAILURE - Eye probabilities not available&quot;)&#10;&#10;            when {&#10;                // SUCCESS: Both eyes clearly closed (blinking)&#10;                leftEyeOpenProbability &lt; BLINK_HIGH_THRESHOLD &amp;&amp; rightEyeOpenProbability &lt; BLINK_HIGH_THRESHOLD -&gt; {&#10;                    println(&quot;DEBUG: Blink SUCCESS - Both eyes closed&quot;)&#10;                    LivenessResult.SUCCESS&#10;                }&#10;                // IN_PROGRESS: One eye closed or both eyes partially closed&#10;                avgEyeOpenProbability &lt; BLINK_LOW_THRESHOLD -&gt; {&#10;                    println(&quot;DEBUG: Blink IN_PROGRESS - Getting closer to blinking&quot;)&#10;                    LivenessResult.IN_PROGRESS&#10;                }&#10;                // FAILURE: Eyes too open&#10;            println(&quot;DEBUG: Smile detection - Probability: $smilingProbability&quot;)&#10;&#10;                else -&gt; {&#10;                    println(&quot;DEBUG: Blink FAILURE - Eyes still open&quot;)&#10;                    LivenessResult.FAILURE&#10;                    println(&quot;DEBUG: Smile SUCCESS - Strong smile detected&quot;)&#10;                }&#10;            }&#10;        } else {&#10;            println(&quot;DEBUG: Blink FAILURE - Eye probabilities not available&quot;)&#10;                    println(&quot;DEBUG: Smile IN_PROGRESS - Moderate smile, needs more&quot;)&#10;            LivenessResult.FAILURE // Cannot determine blink if probabilities are not available&#10;        }&#10;    }&#10;&#10;                    println(&quot;DEBUG: Smile FAILURE - Not smiling enough&quot;)&#10;    /**&#10;     * Verifies if the person is smiling (liveness detection) with progressive feedback&#10;     * @param face Detected face from ML Kit&#10;     * @return LivenessResult indicating smile detection status&#10;            println(&quot;DEBUG: Smile FAILURE - Smile probability not available&quot;)&#10;     */&#10;    fun verifySmile(face: Face): LivenessResult {&#10;        val smilingProbability = face.smilingProbability&#10;&#10;        return if (smilingProbability != null) {&#10;            println(&quot;DEBUG: Smile detection - Probability: $smilingProbability&quot;)&#10;&#10;            when {&#10;                // SUCCESS: Strong smile detected&#10;                smilingProbability &gt; SMILE_HIGH_THRESHOLD -&gt; {&#10;                    println(&quot;DEBUG: Smile SUCCESS - Strong smile detected&quot;)&#10;                    LivenessResult.SUCCESS&#10;                }&#10;                // IN_PROGRESS: Moderate smile, encourage user to smile more&#10;            // DEBUG: Log original face detection info&#10;            println(&quot;DEBUG FaceDetectorHelper: Original bounding box: $boundingBox&quot;)&#10;            println(&quot;DEBUG FaceDetectorHelper: Source image size: ${image.width}x${image.height}&quot;)&#10;&#10;                smilingProbability &gt; SMILE_MEDIUM_THRESHOLD -&gt; {&#10;                    println(&quot;DEBUG: Smile IN_PROGRESS - Moderate smile, needs more&quot;)&#10;                    LivenessResult.IN_PROGRESS&#10;                }&#10;                // FAILURE: Little to no smile&#10;                else -&gt; {&#10;                    println(&quot;DEBUG: Smile FAILURE - Not smiling enough&quot;)&#10;                    LivenessResult.FAILURE&#10;                }&#10;            println(&quot;DEBUG FaceDetectorHelper: Padded coordinates - left:$left, top:$top, right:$right, bottom:$bottom&quot;)&#10;            println(&quot;DEBUG FaceDetectorHelper: Crop dimensions: ${right - left}x${bottom - top}&quot;)&#10;&#10;            }&#10;        } else {&#10;            println(&quot;DEBUG: Smile FAILURE - Smile probability not available&quot;)&#10;            LivenessResult.FAILURE // Cannot determine smile if probability is not available&#10;        }&#10;                println(&quot;DEBUG FaceDetectorHelper: Cropped bitmap size: ${croppedBitmap.width}x${croppedBitmap.height}&quot;)&#10;    }&#10;                // KUNCI PERBAIKAN: Standardisasi ukuran dan format&#10;    /**&#10;                println(&quot;DEBUG FaceDetectorHelper: Standardized bitmap size: ${standardizedBitmap.width}x${standardizedBitmap.height}&quot;)&#10;     * Extracts and preprocesses face bitmap for consistent embedding generation&#10;     * @param face Detected face from ML Kit&#10;     * @param image Source bitmap from camera&#10;     * @return Preprocessed face bitmap or null if extraction fails&#10;     */&#10;    fun extractFaceBitmap(face: Face, image: Bitmap): Bitmap? {&#10;        return try {&#10;            val boundingBox = face.boundingBox&#10;                println(&quot;DEBUG FaceDetectorHelper: Invalid crop area - left:$left &gt;= right:$right or top:$top &gt;= bottom:$bottom&quot;)&#10;&#10;            // DEBUG: Log original face detection info&#10;            println(&quot;DEBUG FaceDetectorHelper: Original bounding box: $boundingBox&quot;)&#10;            println(&quot;DEBUG FaceDetectorHelper: Error extracting face bitmap: ${e.message}&quot;)&#10;            e.printStackTrace()&#10;            println(&quot;DEBUG FaceDetectorHelper: Source image size: ${image.width}x${image.height}&quot;)&#10;&#10;            // Add padding around the face for better context (10% on each side)&#10;            val padding = (boundingBox.width() * 0.1f).toInt()&#10;&#10;            // Calculate expanded bounding box with padding&#10;            val left = maxOf(0, boundingBox.left - padding)&#10;            val top = maxOf(0, boundingBox.top - padding)&#10;            val right = minOf(image.width, boundingBox.right + padding)&#10;            val bottom = minOf(image.height, boundingBox.bottom + padding)&#10;&#10;            println(&quot;DEBUG FaceDetectorHelper: Padded coordinates - left:$left, top:$top, right:$right, bottom:$bottom&quot;)&#10;            println(&quot;DEBUG FaceDetectorHelper: Crop dimensions: ${right - left}x${bottom - top}&quot;)&#10;&#10;            // Validate that we have a valid crop area&#10;            if (left &lt; right &amp;&amp; top &lt; bottom) {&#10;                // Extract face with padding&#10;            println(&quot;Error standardizing face bitmap: ${e.message}&quot;)&#10;                val croppedBitmap =&#10;                    Bitmap.createBitmap(image, left, top, right - left, bottom - top)&#10;                println(&quot;DEBUG FaceDetectorHelper: Cropped bitmap size: ${croppedBitmap.width}x${croppedBitmap.height}&quot;)&#10;&#10;                // KUNCI PERBAIKAN: Standardisasi ukuran dan format&#10;                val standardizedBitmap = standardizeFaceBitmap(croppedBitmap)&#10;                println(&quot;DEBUG FaceDetectorHelper: Standardized bitmap size: ${standardizedBitmap.width}x${standardizedBitmap.height}&quot;)&#10;&#10;                // Clean up intermediate bitmap&#10;                if (croppedBitmap != standardizedBitmap) {&#10;                    croppedBitmap.recycle()&#10;                }&#10;&#10;                standardizedBitmap&#10;            } else {&#10;                println(&quot;DEBUG FaceDetectorHelper: Invalid crop area - left:$left &gt;= right:$right or top:$top &gt;= bottom:$bottom&quot;)&#10;                null&#10;            }&#10;        } catch (e: Exception) {&#10;            println(&quot;DEBUG FaceDetectorHelper: Error extracting face bitmap: ${e.message}&quot;)&#10;            e.printStackTrace()&#10;            null&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Standardizes face bitmap to consistent size and format&#10;     * This ensures consistent preprocessing for both profile and camera images&#10;     */&#10;    private fun standardizeFaceBitmap(faceBitmap: Bitmap): Bitmap {&#10;        // PERBAIKAN: Gunakan ukuran yang sama dengan FaceProcessor (112x112)&#10;        val standardWidth = 112  // Sama dengan IMAGE_SIZE di FaceProcessor&#10;        val standardHeight = 112  // Sama dengan IMAGE_SIZE di FaceProcessor&#10;&#10;        return try {&#10;            // Resize to standard dimensions with high quality&#10;            Bitmap.createScaledBitmap(faceBitmap, standardWidth, standardHeight, true)&#10;        } catch (e: Exception) {&#10;            println(&quot;Error standardizing face bitmap: ${e.message}&quot;)&#10;            faceBitmap // Return original if standardization fails&#10;        }&#10;    }&#10;&#10;        println(&quot;FaceDetectorHelper: Releasing detector resources&quot;)&#10;    /**&#10;     * Checks if a face is well-positioned for verification&#10;     * @param face Detected face&#10;            println(&quot;FaceDetectorHelper: Detector resources released successfully&quot;)&#10;     * @param imageWidth Width of the camera frame&#10;            println(&quot;FaceDetectorHelper: Error during release: ${e.message}&quot;)&#10;     * @param imageHeight Height of the camera frame&#10;     * @return true if face is properly positioned&#10;     */&#10;    fun isFaceWellPositioned(face: Face, imageWidth: Int, imageHeight: Int): Boolean {&#10;        val boundingBox = face.boundingBox&#10;        val faceWidth = boundingBox.width()&#10;        val faceHeight = boundingBox.height()&#10;&#10;        // Check if face is not too small or too large&#10;        val minFaceSize = minOf(imageWidth, imageHeight) * 0.2f&#10;        val maxFaceSize = minOf(imageWidth, imageHeight) * 0.8f&#10;        val faceSize = minOf(faceWidth, faceHeight)&#10;&#10;        if (faceSize &lt; minFaceSize || faceSize &gt; maxFaceSize) {&#10;            return false&#10;        }&#10;&#10;        // Check if face is roughly centered&#10;        val faceCenterX = boundingBox.centerX()&#10;        val faceCenterY = boundingBox.centerY()&#10;        val imageCenterX = imageWidth / 2f&#10;        val imageCenterY = imageHeight / 2f&#10;&#10;        val maxOffsetX = imageWidth * 0.25f&#10;        val maxOffsetY = imageHeight * 0.25f&#10;&#10;        return kotlin.math.abs(faceCenterX - imageCenterX) &lt; maxOffsetX &amp;&amp;&#10;                kotlin.math.abs(faceCenterY - imageCenterY) &lt; maxOffsetY&#10;    }&#10;&#10;    /**&#10;     * Clean up resources when done&#10;     * PERBAIKAN: Tambahkan null check&#10;     */&#10;    fun release() {&#10;        println(&quot;FaceDetectorHelper: Releasing detector resources&quot;)&#10;        try {&#10;            _faceDetector?.close()&#10;            _faceDetector = null&#10;            println(&quot;FaceDetectorHelper: Detector resources released successfully&quot;)&#10;        } catch (e: Exception) {&#10;            println(&quot;FaceDetectorHelper: Error during release: ${e.message}&quot;)&#10;        }&#10;    }&#10;}&#10;" />
              <option name="updatedContent" value="package com.example.infinite_track.data.face&#10;&#10;import android.graphics.Bitmap&#10;import androidx.annotation.OptIn&#10;import androidx.camera.core.ExperimentalGetImage&#10;import androidx.camera.core.ImageProxy&#10;import com.google.mlkit.vision.common.InputImage&#10;import com.google.mlkit.vision.face.Face&#10;import com.google.mlkit.vision.face.FaceDetection&#10;import com.google.mlkit.vision.face.FaceDetector&#10;import com.google.mlkit.vision.face.FaceDetectorOptions&#10;import javax.inject.Inject&#10;import javax.inject.Singleton&#10;&#10;/**&#10; * Enum for liveness detection results&#10; * Provides progressive feedback for user guidance&#10; */&#10;enum class LivenessResult {&#10;    SUCCESS,    // Liveness detected successfully&#10;    IN_PROGRESS, // User is on the right track, needs slight adjustment&#10;    FAILURE     // Liveness not detected&#10;}&#10;&#10;/**&#10; * Helper class for ML Kit Face Detection operations&#10; * Handles face detection, liveness verification (blink/smile), and face extraction&#10; * FIXED: Added proper reinitialization support&#10; */&#10;@Singleton&#10;class FaceDetectorHelper @Inject constructor() {&#10;&#10;    companion object {&#10;        // More flexible thresholds for progressive feedback&#10;        private const val BLINK_HIGH_THRESHOLD = 0.4f // Original threshold for SUCCESS&#10;        private const val BLINK_LOW_THRESHOLD = 0.6f  // Lower threshold for IN_PROGRESS&#10;&#10;        private const val SMILE_HIGH_THRESHOLD = 0.7f // Original threshold for SUCCESS&#10;        private const val SMILE_MEDIUM_THRESHOLD = 0.4f // Medium threshold for IN_PROGRESS&#10;    }&#10;&#10;    // PERBAIKAN: Buat detector nullable dan reinitializable&#10;    private var _faceDetector: FaceDetector? = null&#10;&#10;    // Property untuk mengakses detector yang selalu valid&#10;    private val faceDetector: FaceDetector&#10;        get() {&#10;            // Jika detector null atau sudah closed, buat yang baru&#10;            if (_faceDetector == null) {&#10;                _faceDetector = createNewDetector()&#10;            }&#10;            return _faceDetector!!&#10;        }&#10;&#10;    /**&#10;     * Create new ML Kit Face Detector instance&#10;     */&#10;    private fun createNewDetector(): FaceDetector {&#10;        val options = FaceDetectorOptions.Builder()&#10;            .setPerformanceMode(FaceDetectorOptions.PERFORMANCE_MODE_FAST)&#10;            .setLandmarkMode(FaceDetectorOptions.LANDMARK_MODE_ALL)&#10;            .setClassificationMode(FaceDetectorOptions.CLASSIFICATION_MODE_ALL)&#10;            .setMinFaceSize(0.15f) // Minimum face size relative to image&#10;            .enableTracking() // Enable face tracking for better performance&#10;            .build()&#10;&#10;        return FaceDetection.getClient(options)&#10;    }&#10;&#10;    /**&#10;     * Force reinitialize detector - call this when reset is needed&#10;     */&#10;    fun reinitialize() {&#10;        try {&#10;            _faceDetector?.close()&#10;        } catch (e: Exception) {&#10;            // Silently handle close errors&#10;        }&#10;        _faceDetector = null&#10;        // Detector akan dibuat ulang saat pertama kali diakses&#10;    }&#10;&#10;    /**&#10;     * Detects faces in the given image frame&#10;     * @param imageProxy Camera image frame from CameraX&#10;     * @param onResult Callback with detection result&#10;     */&#10;    @OptIn(ExperimentalGetImage::class)&#10;    fun detect(imageProxy: ImageProxy, onResult: (Result&lt;Face&gt;) -&gt; Unit) {&#10;        val mediaImage = imageProxy.image&#10;        if (mediaImage != null) {&#10;            val image = InputImage.fromMediaImage(mediaImage, imageProxy.imageInfo.rotationDegrees)&#10;&#10;            try {&#10;                // Gunakan property yang akan otomatis reinitialize jika perlu&#10;                val detector = faceDetector&#10;&#10;                detector.process(image)&#10;                    .addOnSuccessListener { faces -&gt;&#10;                        if (faces.isNotEmpty()) {&#10;                            // Return the first (largest) detected face&#10;                            val largestFace =&#10;                                faces.maxByOrNull { it.boundingBox.width() * it.boundingBox.height() }&#10;                            if (largestFace != null) {&#10;                                onResult(Result.success(largestFace))&#10;                            } else {&#10;                                onResult(Result.failure(Exception(&quot;No valid face detected&quot;)))&#10;                            }&#10;                        } else {&#10;                            onResult(Result.failure(Exception(&quot;No faces detected&quot;)))&#10;                        }&#10;                    }&#10;                    .addOnFailureListener { exception -&gt;&#10;                        // Jika detector closed, coba reinitialize&#10;                        if (exception.message?.contains(&quot;closed&quot;) == true) {&#10;                            reinitialize()&#10;                            onResult(Result.failure(Exception(&quot;Detector was closed, please try again&quot;)))&#10;                        } else {&#10;                            onResult(Result.failure(exception))&#10;                        }&#10;                    }&#10;                    .addOnCompleteListener {&#10;                        // Clean up resources - ALWAYS close imageProxy here&#10;                        imageProxy.close()&#10;                    }&#10;            } catch (e: Exception) {&#10;                if (e.message?.contains(&quot;closed&quot;) == true) {&#10;                    reinitialize()&#10;                }&#10;                onResult(Result.failure(e))&#10;                imageProxy.close()&#10;            }&#10;        } else {&#10;            onResult(Result.failure(Exception(&quot;Image is null&quot;)))&#10;            imageProxy.close()&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Verifies if the person is blinking (liveness detection) with progressive feedback&#10;     * @param face Detected face from ML Kit&#10;     * @return LivenessResult indicating blink detection status&#10;     */&#10;    fun verifyBlink(face: Face): LivenessResult {&#10;        val leftEyeOpenProbability = face.leftEyeOpenProbability&#10;        val rightEyeOpenProbability = face.rightEyeOpenProbability&#10;&#10;        return if (leftEyeOpenProbability != null &amp;&amp; rightEyeOpenProbability != null) {&#10;            val avgEyeOpenProbability = (leftEyeOpenProbability + rightEyeOpenProbability) / 2f&#10;&#10;            when {&#10;                // SUCCESS: Both eyes clearly closed (blinking)&#10;                leftEyeOpenProbability &lt; BLINK_HIGH_THRESHOLD &amp;&amp; rightEyeOpenProbability &lt; BLINK_HIGH_THRESHOLD -&gt; {&#10;                    LivenessResult.SUCCESS&#10;                }&#10;                // IN_PROGRESS: One eye closed or both eyes partially closed&#10;                avgEyeOpenProbability &lt; BLINK_LOW_THRESHOLD -&gt; {&#10;                    LivenessResult.IN_PROGRESS&#10;                }&#10;                // FAILURE: Eyes too open&#10;                else -&gt; {&#10;                    LivenessResult.FAILURE&#10;                }&#10;            }&#10;        } else {&#10;            LivenessResult.FAILURE // Cannot determine blink if probabilities are not available&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Verifies if the person is smiling (liveness detection) with progressive feedback&#10;     * @param face Detected face from ML Kit&#10;     * @return LivenessResult indicating smile detection status&#10;     */&#10;    fun verifySmile(face: Face): LivenessResult {&#10;        val smilingProbability = face.smilingProbability&#10;&#10;        return if (smilingProbability != null) {&#10;            when {&#10;                // SUCCESS: Strong smile detected&#10;                smilingProbability &gt; SMILE_HIGH_THRESHOLD -&gt; {&#10;                    LivenessResult.SUCCESS&#10;                }&#10;                // IN_PROGRESS: Moderate smile, encourage user to smile more&#10;                smilingProbability &gt; SMILE_MEDIUM_THRESHOLD -&gt; {&#10;                    LivenessResult.IN_PROGRESS&#10;                }&#10;                // FAILURE: Little to no smile&#10;                else -&gt; {&#10;                    LivenessResult.FAILURE&#10;                }&#10;            }&#10;        } else {&#10;            LivenessResult.FAILURE // Cannot determine smile if probability is not available&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Extracts and preprocesses face bitmap for consistent embedding generation&#10;     * @param face Detected face from ML Kit&#10;     * @param image Source bitmap from camera&#10;     * @return Preprocessed face bitmap or null if extraction fails&#10;     */&#10;    fun extractFaceBitmap(face: Face, image: Bitmap): Bitmap? {&#10;        return try {&#10;            val boundingBox = face.boundingBox&#10;&#10;            // Add padding around the face for better context (10% on each side)&#10;            val padding = (boundingBox.width() * 0.1f).toInt()&#10;&#10;            // Calculate expanded bounding box with padding&#10;            val left = maxOf(0, boundingBox.left - padding)&#10;            val top = maxOf(0, boundingBox.top - padding)&#10;            val right = minOf(image.width, boundingBox.right + padding)&#10;            val bottom = minOf(image.height, boundingBox.bottom + padding)&#10;&#10;            // Validate that we have a valid crop area&#10;            if (left &lt; right &amp;&amp; top &lt; bottom) {&#10;                // Extract face with padding&#10;                val croppedBitmap =&#10;                    Bitmap.createBitmap(image, left, top, right - left, bottom - top)&#10;&#10;                // Standardisasi ukuran dan format&#10;                val standardizedBitmap = standardizeFaceBitmap(croppedBitmap)&#10;&#10;                // Clean up intermediate bitmap&#10;                if (croppedBitmap != standardizedBitmap) {&#10;                    croppedBitmap.recycle()&#10;                }&#10;&#10;                standardizedBitmap&#10;            } else {&#10;                null&#10;            }&#10;        } catch (e: Exception) {&#10;            null&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Standardizes face bitmap to consistent size and format&#10;     * This ensures consistent preprocessing for both profile and camera images&#10;     */&#10;    private fun standardizeFaceBitmap(faceBitmap: Bitmap): Bitmap {&#10;        // PERBAIKAN: Gunakan ukuran yang sama dengan FaceProcessor (112x112)&#10;        val standardWidth = 112  // Sama dengan IMAGE_SIZE di FaceProcessor&#10;        val standardHeight = 112  // Sama dengan IMAGE_SIZE di FaceProcessor&#10;&#10;        return try {&#10;            // Resize to standard dimensions with high quality&#10;            Bitmap.createScaledBitmap(faceBitmap, standardWidth, standardHeight, true)&#10;        } catch (e: Exception) {&#10;            faceBitmap // Return original if standardization fails&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Checks if a face is well-positioned for verification&#10;     * @param face Detected face&#10;     * @param imageWidth Width of the camera frame&#10;     * @param imageHeight Height of the camera frame&#10;     * @return true if face is properly positioned&#10;     */&#10;    fun isFaceWellPositioned(face: Face, imageWidth: Int, imageHeight: Int): Boolean {&#10;        val boundingBox = face.boundingBox&#10;        val faceWidth = boundingBox.width()&#10;        val faceHeight = boundingBox.height()&#10;&#10;        // Check if face is not too small or too large&#10;        val minFaceSize = minOf(imageWidth, imageHeight) * 0.2f&#10;        val maxFaceSize = minOf(imageWidth, imageHeight) * 0.8f&#10;        val faceSize = minOf(faceWidth, faceHeight)&#10;&#10;        if (faceSize &lt; minFaceSize || faceSize &gt; maxFaceSize) {&#10;            return false&#10;        }&#10;&#10;        // Check if face is roughly centered&#10;        val faceCenterX = boundingBox.centerX()&#10;        val faceCenterY = boundingBox.centerY()&#10;        val imageCenterX = imageWidth / 2f&#10;        val imageCenterY = imageHeight / 2f&#10;&#10;        val maxOffsetX = imageWidth * 0.25f&#10;        val maxOffsetY = imageHeight * 0.25f&#10;&#10;        return kotlin.math.abs(faceCenterX - imageCenterX) &lt; maxOffsetX &amp;&amp;&#10;                kotlin.math.abs(faceCenterY - imageCenterY) &lt; maxOffsetY&#10;    }&#10;&#10;    /**&#10;     * Clean up resources when done&#10;     * PERBAIKAN: Tambahkan null check&#10;     */&#10;    fun release() {&#10;        try {&#10;            _faceDetector?.close()&#10;            _faceDetector = null&#10;        } catch (e: Exception) {&#10;        }&#10;    }&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/app/src/main/java/com/example/infinite_track/data/repository/attendance/AttendanceRepositoryImpl.kt">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/app/src/main/java/com/example/infinite_track/data/repository/attendance/AttendanceRepositoryImpl.kt" />
              <option name="originalContent" value="package com.example.infinite_track.data.repository.attendance&#10;&#10;import android.util.Log&#10;import com.example.infinite_track.data.mapper.attendance.toActiveSession&#10;import com.example.infinite_track.data.mapper.attendance.toDomain&#10;import com.example.infinite_track.data.mapper.attendance.toDto&#10;import com.example.infinite_track.data.soucre.local.preferences.AttendancePreference&#10;import com.example.infinite_track.data.soucre.network.request.CheckOutRequestDto&#10;import com.example.infinite_track.data.soucre.network.request.LocationEventRequest&#10;import com.example.infinite_track.data.soucre.network.retrofit.ApiService&#10;import com.example.infinite_track.domain.model.attendance.ActiveAttendanceSession&#10;import com.example.infinite_track.domain.model.attendance.AttendanceRequestModel&#10;import com.example.infinite_track.domain.model.attendance.TodayStatus&#10;import com.example.infinite_track.domain.repository.AttendanceRepository&#10;import kotlinx.coroutines.flow.first&#10;&#10;@Singleton&#10;class AttendanceRepositoryImpl @Inject constructor(&#10;    private val apiService: ApiService,&#10;    private val attendancePreference: AttendancePreference&#10;) : AttendanceRepository {&#10;&#10;    companion object {&#10;        private const val TAG = &quot;AttendanceRepository&quot;&#10;    }&#10;&#10;    /**&#10;     * Gets the current day's attendance status&#10;            // Convert domain model to DTO using mapper&#10;            val requestDto = request.toDto()&#10;&#10;            // Call API for check-in - backend handles location validation&#10;            val response = apiService.checkIn(requestDto)&#10;&#10;            if (response.success) {&#10;                // Save the attendance ID for later checkout&#10;                attendancePreference.saveActiveAttendanceId(response.data.idAttendance)&#10;                Log.d(&#10;                    TAG,&#10;                    &quot;Check-in successful, saved attendance ID: ${response.data.idAttendance}&quot;&#10;            } else {&#10;                Result.failure(Exception(response.message))&#10;            }&#10;        } catch (e: Exception) {&#10;            Log.e(TAG, &quot;Error during check-in&quot;, e)&#10;            Result.failure(e)&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Performs check-out operation with attendanceId and coordinates&#10;     * Backend will handle location validation for checkout&#10;     */&#10;    override suspend fun checkOut(&#10;        attendanceId: Int,&#10;        latitude: Double,&#10;        longitude: Double&#10;    ): Result&lt;ActiveAttendanceSession&gt; {&#10;        return try {&#10;            // Create checkout request DTO with coordinates&#10;            val checkOutRequestDto = CheckOutRequestDto(&#10;                latitude = latitude,&#10;                longitude = longitude&#10;            )&#10;&#10;            // Call API for check-out with attendanceId in URL and coordinates in body&#10;            val response = apiService.checkOut(attendanceId, checkOutRequestDto)&#10;&#10;            if (response.success) {&#10;                // Clear the active attendance ID&#10;                attendancePreference.clearActiveAttendanceId()&#10;            } else {&#10;                Result.failure(Exception(response.message))&#10;            }&#10;        } catch (e: Exception) {&#10;            Log.e(TAG, &quot;Error during check-out&quot;, e)&#10;            Result.failure(e)&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Retrieves the active attendance ID from preferences&#10;     */&#10;    override suspend fun getActiveAttendanceId(): Int? {&#10;        return try {&#10;            attendancePreference.getActiveAttendanceId().first()&#10;        } catch (e: Exception) {&#10;            Log.e(TAG, &quot;Error getting active attendance ID&quot;, e)&#10;            null&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Sends location event (ENTER/EXIT) to backend&#10;     */&#10;    override suspend fun sendLocationEvent(request: LocationEventRequest): Result&lt;Unit&gt; {&#10;        return try {&#10;            val response = apiService.sendLocationEvent(request)&#10;            if (response.isSuccessful) {&#10;                Log.d(TAG, &quot;Location event sent successfully: ${request.eventType}&quot;)&#10;                Result.success(Unit)&#10;            } else {&#10;                Result.failure(Exception(&quot;Failed to send location event: ${response.code()} ${response.message()}&quot;))&#10;            }&#10;        } catch (e: Exception) {&#10;            Log.e(TAG, &quot;Error sending location event&quot;, e)&#10;" />
              <option name="updatedContent" value="package com.example.infinite_track.data.repository.attendance&#10;&#10;import android.util.Log&#10;import com.example.infinite_track.data.mapper.attendance.toActiveSession&#10;import com.example.infinite_track.data.mapper.attendance.toDomain&#10;import com.example.infinite_track.data.mapper.attendance.toDto&#10;import com.example.infinite_track.data.soucre.local.preferences.AttendancePreference&#10;import com.example.infinite_track.data.soucre.network.request.CheckOutRequestDto&#10;import com.example.infinite_track.data.soucre.network.request.LocationEventRequest&#10;import com.example.infinite_track.data.soucre.network.retrofit.ApiService&#10;import com.example.infinite_track.domain.model.attendance.ActiveAttendanceSession&#10;import com.example.infinite_track.domain.model.attendance.AttendanceRequestModel&#10;import com.example.infinite_track.domain.model.attendance.TodayStatus&#10;import com.example.infinite_track.domain.repository.AttendanceRepository&#10;import kotlinx.coroutines.flow.first&#10;import org.json.JSONObject&#10;import retrofit2.HttpException&#10;import javax.inject.Inject&#10;import javax.inject.Singleton&#10;&#10;@Singleton&#10;class AttendanceRepositoryImpl @Inject constructor(&#10;    private val apiService: ApiService,&#10;    private val attendancePreference: AttendancePreference&#10;) : AttendanceRepository {&#10;&#10;    companion object {&#10;        private const val TAG = &quot;AttendanceRepository&quot;&#10;    }&#10;&#10;    /**&#10;     * Extract error message from HTTP response body&#10;     */&#10;    private fun extractErrorMessage(exception: HttpException): String {&#10;        return try {&#10;            val errorBody = exception.response()?.errorBody()?.string()&#10;            if (!errorBody.isNullOrEmpty()) {&#10;                val jsonObject = JSONObject(errorBody)&#10;                val message = jsonObject.optString(&quot;message&quot;, &quot;&quot;)&#10;                if (message.isNotEmpty()) {&#10;                    Log.d(TAG, &quot;Extracted error message: $message&quot;)&#10;                    return message&#10;                }&#10;            }&#10;            // Fallback to HTTP status message&#10;            &quot;HTTP ${exception.code()} ${exception.message()}&quot;&#10;        } catch (e: Exception) {&#10;            Log.e(TAG, &quot;Failed to extract error message&quot;, e)&#10;            &quot;HTTP ${exception.code()} ${exception.message()}&quot;&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Gets the current day's attendance status&#10;     */&#10;    override suspend fun getTodayStatus(): Result&lt;TodayStatus&gt; {&#10;        return try {&#10;            val response = apiService.getTodayStatus()&#10;            if (response.success) {&#10;                // Convert DTO to domain model using mapper&#10;                Result.success(response.data.toDomain())&#10;            } else {&#10;                Result.failure(Exception(response.message ?: &quot;Unknown error&quot;))&#10;            }&#10;        } catch (e: HttpException) {&#10;            Log.e(TAG, &quot;HTTP Error getting today's status&quot;, e)&#10;            val errorMessage = extractErrorMessage(e)&#10;            Result.failure(Exception(errorMessage))&#10;        } catch (e: Exception) {&#10;            Log.e(TAG, &quot;Error getting today's status&quot;, e)&#10;            Result.failure(e)&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Performs check-in operation - simplified without client-side location validation&#10;     * Backend will handle all location validation&#10;     */&#10;    override suspend fun checkIn(request: AttendanceRequestModel): Result&lt;ActiveAttendanceSession&gt; {&#10;        return try {&#10;            // Convert domain model to DTO using mapper&#10;            val requestDto = request.toDto()&#10;&#10;            // Call API for check-in - backend handles location validation&#10;            val response = apiService.checkIn(requestDto)&#10;&#10;            if (response.success) {&#10;                // Save the attendance ID for later checkout&#10;                attendancePreference.saveActiveAttendanceId(response.data.idAttendance)&#10;                Log.d(&#10;                    TAG,&#10;                    &quot;Check-in successful, saved attendance ID: ${response.data.idAttendance}&quot;&#10;                )&#10;&#10;                // Convert DTO to ActiveAttendanceSession domain model using mapper&#10;                Result.success(response.data.toActiveSession())&#10;            } else {&#10;                Result.failure(Exception(response.message))&#10;            }&#10;        } catch (e: HttpException) {&#10;            Log.e(TAG, &quot;HTTP Error during check-in&quot;, e)&#10;            val errorMessage = extractErrorMessage(e)&#10;            Result.failure(Exception(errorMessage))&#10;        } catch (e: Exception) {&#10;            Log.e(TAG, &quot;Error during check-in&quot;, e)&#10;            Result.failure(e)&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Performs check-out operation with attendanceId and coordinates&#10;     * Backend will handle location validation for checkout&#10;     */&#10;    override suspend fun checkOut(&#10;        attendanceId: Int,&#10;        latitude: Double,&#10;        longitude: Double&#10;    ): Result&lt;ActiveAttendanceSession&gt; {&#10;        return try {&#10;            // Create checkout request DTO with coordinates&#10;            val checkOutRequestDto = CheckOutRequestDto(&#10;                latitude = latitude,&#10;                longitude = longitude&#10;            )&#10;&#10;            // Call API for check-out with attendanceId in URL and coordinates in body&#10;            val response = apiService.checkOut(attendanceId, checkOutRequestDto)&#10;&#10;            if (response.success) {&#10;                // Clear the active attendance ID&#10;                attendancePreference.clearActiveAttendanceId()&#10;                Log.d(TAG, &quot;Check-out successful, cleared attendance ID&quot;)&#10;&#10;                // Convert DTO to ActiveAttendanceSession domain model using mapper&#10;                Result.success(response.data.toActiveSession())&#10;            } else {&#10;                Result.failure(Exception(response.message))&#10;            }&#10;        } catch (e: HttpException) {&#10;            Log.e(TAG, &quot;HTTP Error during check-out&quot;, e)&#10;            val errorMessage = extractErrorMessage(e)&#10;            Result.failure(Exception(errorMessage))&#10;        } catch (e: Exception) {&#10;            Log.e(TAG, &quot;Error during check-out&quot;, e)&#10;            Result.failure(e)&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Retrieves the active attendance ID from preferences&#10;     */&#10;    override suspend fun getActiveAttendanceId(): Int? {&#10;        return try {&#10;            attendancePreference.getActiveAttendanceId().first()&#10;        } catch (e: Exception) {&#10;            Log.e(TAG, &quot;Error getting active attendance ID&quot;, e)&#10;            null&#10;        }&#10;    }&#10;&#10;    /**&#10;     * Sends location event (ENTER/EXIT) to backend&#10;     */&#10;    override suspend fun sendLocationEvent(request: LocationEventRequest): Result&lt;Unit&gt; {&#10;        return try {&#10;            val response = apiService.sendLocationEvent(request)&#10;            if (response.isSuccessful) {&#10;                Log.d(TAG, &quot;Location event sent successfully: ${request.eventType}&quot;)&#10;                Result.success(Unit)&#10;            } else {&#10;                Result.failure(Exception(&quot;Failed to send location event: ${response.code()} ${response.message()}&quot;))&#10;            }&#10;        } catch (e: Exception) {&#10;            Log.e(TAG, &quot;Error sending location event&quot;, e)&#10;            Result.failure(e)&#10;        }&#10;    }&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>